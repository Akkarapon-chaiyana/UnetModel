{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-3nyZokaHtnz"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models, transforms\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
        "import time\n",
        "# Install torchinfo, import if it's available\n",
        "try:\n",
        "  import torchinfo\n",
        "except:\n",
        "  !pip install torchinfo\n",
        "  import torchinfo\n",
        "\n",
        "from torchinfo import summary\n",
        "\n",
        "# Install torchinfo, import if it's available\n",
        "try:\n",
        "  import rasterio\n",
        "except:\n",
        "  !pip install rasterio\n",
        "  import rasterio\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from rasterio.transform import Affine\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v1o7RAEJIUuF"
      },
      "outputs": [],
      "source": [
        "!rm -r /content/drive/MyDrive/Patches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fp4Obwp5IUws"
      },
      "outputs": [],
      "source": [
        "from affine import Affine\n",
        "import os\n",
        "import rasterio\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define paths\n",
        "path_rgb = '/content/drive/MyDrive/Theos/RGB.tif'\n",
        "path_mask = '/content/drive/MyDrive/Theos/mask.tif'\n",
        "save_dir = '/content/drive/MyDrive/Patches'\n",
        "\n",
        "# Define patch size and stride\n",
        "patch_size = 256\n",
        "stride = 128\n",
        "\n",
        "# Load RGB and mask images\n",
        "with rasterio.open(path_rgb) as src_rgb:\n",
        "    rgb_data = src_rgb.read().transpose(1, 2, 0)\n",
        "    rgb_meta = src_rgb.meta.copy()\n",
        "\n",
        "with rasterio.open(path_mask) as src_mask:\n",
        "    mask_data = src_mask.read(1)\n",
        "    mask_meta = src_mask.meta.copy()\n",
        "\n",
        "# Define affine transformation for patch images\n",
        "transform = src_rgb.transform\n",
        "\n",
        "# Extract patches with coordinates\n",
        "def extract_patches(image, patch_size, stride):\n",
        "    patches = []\n",
        "    coordinates = []\n",
        "    height, width = image.shape[:2]\n",
        "    for y in range(0, height - patch_size + 1, stride):\n",
        "        for x in range(0, width - patch_size + 1, stride):\n",
        "            patch = image[y:y + patch_size, x:x + patch_size]\n",
        "            patches.append(patch)\n",
        "            coordinates.append((x, y))\n",
        "    return patches, coordinates\n",
        "\n",
        "rgb_patches, rgb_coordinates = extract_patches(rgb_data, patch_size, stride)\n",
        "mask_patches, mask_coordinates = extract_patches(mask_data, patch_size, stride)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F_t9ESuYIUzN"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "import rasterio\n",
        "from rasterio.transform import Affine\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "rgb_train, rgb_val, mask_train, mask_val = train_test_split(rgb_patches, mask_patches, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create directories to save patches\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "os.makedirs(os.path.join(save_dir, 'train', 'rgb'), exist_ok=True)  # Create the 'train/rgb' directory\n",
        "os.makedirs(os.path.join(save_dir, 'train', 'mask'), exist_ok=True)  # Create the 'train/mask' directory\n",
        "os.makedirs(os.path.join(save_dir, 'val', 'rgb'), exist_ok=True)  # Create the 'val/rgb' directory\n",
        "os.makedirs(os.path.join(save_dir, 'val', 'mask'), exist_ok=True)  # Create the 'val/mask' directory\n",
        "\n",
        "# Function to save patches with metadata\n",
        "def save_patches(patches, meta, coordinates, path_template):\n",
        "    for i, (patch, (x, y)) in enumerate(zip(patches, coordinates)):\n",
        "        patch_path = path_template.format(i)\n",
        "        # Update metadata to reflect correct coordinates\n",
        "        meta_copy = meta.copy()\n",
        "        meta_copy['transform'] = Affine.translation(x, y) * transform\n",
        "        with rasterio.open(\n",
        "            patch_path,\n",
        "            'w',\n",
        "            driver='GTiff',\n",
        "            height=patch.shape[0],\n",
        "            width=patch.shape[1],\n",
        "            count=3 if len(patch.shape) == 3 else 1,  # Check if RGB or single band\n",
        "            dtype=patch.dtype,\n",
        "            crs=meta_copy['crs'],\n",
        "            transform=meta_copy['transform'],\n",
        "        ) as dst:\n",
        "            if len(patch.shape) == 3:\n",
        "                dst.write(patch.transpose(2, 0, 1))  # Write the RGB patch to the file\n",
        "            else:\n",
        "                dst.write(patch, 1)  # Write the mask patch to the file\n",
        "\n",
        "# Save training patches with metadata\n",
        "save_patches(rgb_train, rgb_meta, rgb_coordinates, os.path.join(save_dir, 'train', 'rgb', 'rgb_{}.tif'))\n",
        "save_patches(mask_train, mask_meta, mask_coordinates, os.path.join(save_dir, 'train', 'mask', 'mask_{}.tif'))\n",
        "\n",
        "# Save validation patches with metadata\n",
        "save_patches(rgb_val, rgb_meta, rgb_coordinates, os.path.join(save_dir, 'val', 'rgb', 'rgb_{}.tif'))\n",
        "save_patches(mask_val, mask_meta, mask_coordinates, os.path.join(save_dir, 'val', 'mask', 'mask_{}.tif'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Wx9RmICIU1f"
      },
      "outputs": [],
      "source": [
        "class SegmentationDataset(Dataset):\n",
        "    def __init__(self, image_dir, mask_dir, transform=None):\n",
        "        self.image_dir = image_dir\n",
        "        self.mask_dir = mask_dir\n",
        "        self.transform = transform\n",
        "        self.images = [img for img in os.listdir(image_dir) if img.endswith('.tif')]\n",
        "        self.masks = [mask for mask in os.listdir(mask_dir) if mask.endswith('.tif')]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.image_dir, self.images[idx])\n",
        "        mask_path = os.path.join(self.mask_dir, self.masks[idx])\n",
        "        image = Image.open(img_path)\n",
        "        mask = Image.open(mask_path)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "            mask = self.transform(mask)\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = SegmentationDataset('/content/drive/MyDrive/Patches/train/rgb', '/content/drive/MyDrive/Patches/train/mask', transform=transform)\n",
        "val_dataset = SegmentationDataset('/content/drive/MyDrive/Patches/val/rgb', '/content/drive/MyDrive/Patches/val/mask', transform=transform)\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HaRC6AQUIU_6"
      },
      "outputs": [],
      "source": [
        "image, masked = next(iter(train_loader))\n",
        "print(image.shape, masked.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ckJMdll6IVCo"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Assuming you have defined `PatchDataset`, `transform`, `train_loader`, `val_loader`, and `get_model` as in your previous code snippet\n",
        "\n",
        "# Get the length of the dataset\n",
        "dataset_length = len(train_loader.dataset)\n",
        "\n",
        "# Randomly select an index\n",
        "index = np.random.randint(dataset_length)\n",
        "\n",
        "# Get the image and mask at the selected index\n",
        "image, mask = train_loader.dataset[index]\n",
        "\n",
        "\n",
        "images_normalized = image.numpy().transpose(1, 2, 0)\n",
        "\n",
        "\n",
        "# Convert the mask tensor to numpy array\n",
        "mask = mask.numpy().transpose(1, 2, 0)\n",
        "\n",
        "# Create a figure with two subplots\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
        "\n",
        "# Plot the image\n",
        "ax1.imshow(images_normalized)\n",
        "ax1.axis('off')\n",
        "ax1.set_title('Input Image')\n",
        "\n",
        "# Plot the mask\n",
        "ax2.imshow(mask, cmap='gray')\n",
        "ax2.axis('off')\n",
        "ax2.set_title('Mask')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WamkK0Jn13Uo"
      },
      "source": [
        "## Applied simple UNET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MZIy9p22IVM1"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow keras opencv-python rasterio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Piu-myaeuIAE"
      },
      "outputs": [],
      "source": [
        "!pip3 install opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NYKq4bbyuH9u"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import rasterio\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "def load_tiff_image(file_path):\n",
        "    with rasterio.open(file_path) as src:\n",
        "        return src.read().transpose(1, 2, 0)\n",
        "\n",
        "def preprocess_images(images_path, masks_path, image_size):\n",
        "    images = []\n",
        "    masks = []\n",
        "\n",
        "    image_files = sorted([os.path.join(images_path, f) for f in os.listdir(images_path) if f.endswith('.tif')])\n",
        "    mask_files = sorted([os.path.join(masks_path, f) for f in os.listdir(masks_path) if f.endswith('.tif')])\n",
        "\n",
        "    for img_file, mask_file in zip(image_files, mask_files):\n",
        "        image = load_tiff_image(img_file)\n",
        "        mask = load_tiff_image(mask_file)\n",
        "\n",
        "        image = cv2.resize(image, (image_size, image_size))\n",
        "        mask = cv2.resize(mask, (image_size, image_size))\n",
        "\n",
        "        images.append(image)\n",
        "        masks.append(mask)\n",
        "\n",
        "    return np.array(images), np.array(masks)\n",
        "\n",
        "image_size = 256\n",
        "train_images, train_masks = preprocess_images('/content/drive/MyDrive/Patches/train/rgb',\n",
        "                                              '/content/drive/MyDrive/Patches/train/mask',\n",
        "                                              image_size)\n",
        "\n",
        "val_images, val_masks = preprocess_images('/content/drive/MyDrive/Patches/val/rgb',\n",
        "                                          '/content/drive/MyDrive/Patches/val/mask',\n",
        "                                          image_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UMB7EhaPuIE1"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Concatenate, Input\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "def unet_model(input_size=(256, 256, 3)):\n",
        "    inputs = Input(input_size)\n",
        "\n",
        "    # Encoding\n",
        "    conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "    conv2 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool1)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "    conv3 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool2)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "\n",
        "    # Bottleneck\n",
        "    conv4 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool3)\n",
        "\n",
        "    # Decoding\n",
        "    up5 = UpSampling2D(size=(2, 2))(conv4)\n",
        "    merge5 = Concatenate()([conv3, up5])\n",
        "    conv5 = Conv2D(256, (3, 3), activation='relu', padding='same')(merge5)\n",
        "\n",
        "    up6 = UpSampling2D(size=(2, 2))(conv5)\n",
        "    merge6 = Concatenate()([conv2, up6])\n",
        "    conv6 = Conv2D(128, (3, 3), activation='relu', padding='same')(merge6)\n",
        "\n",
        "    up7 = UpSampling2D(size=(2, 2))(conv6)\n",
        "    merge7 = Concatenate()([conv1, up7])\n",
        "    conv7 = Conv2D(64, (3, 3), activation='relu', padding='same')(merge7)\n",
        "\n",
        "    conv8 = Conv2D(1, (1, 1), activation='sigmoid')(conv7)\n",
        "\n",
        "    model = Model(inputs, conv8)\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "model = unet_model()\n",
        "model.summary()\n",
        "\n",
        "model.fit(train_images, train_masks, validation_data=(val_images, val_masks), epochs=10, batch_size=8)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q5ccI4BduIHX"
      },
      "outputs": [],
      "source": [
        "loss, acc = model.evaluate(val_images, val_masks)\n",
        "print(f\"Validation Loss: {loss}\")\n",
        "print(f\"Validation Accuracy: {acc}\")\n",
        "\n",
        "predictions = model.predict(val_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JV8PwTEWuIJt"
      },
      "outputs": [],
      "source": [
        "def display_images(images, masks, predictions, num_images=3):\n",
        "    num_images = min(num_images, len(images))  # Ensure num_images does not exceed the length of images\n",
        "\n",
        "    for i in range(num_images):\n",
        "        plt.figure(figsize=(15, 5))\n",
        "\n",
        "        plt.subplot(1, 3, 1)\n",
        "        plt.imshow(images[i])\n",
        "        plt.title('Original Image')\n",
        "\n",
        "        plt.subplot(1, 3, 2)\n",
        "        plt.imshow(masks[i].squeeze(), cmap='gray')\n",
        "        plt.title('Mask')\n",
        "\n",
        "        plt.subplot(1, 3, 3)\n",
        "        plt.imshow(predictions[i].squeeze(), cmap='gray')\n",
        "        plt.title('Prediction')\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "# Adjust num_images to the actual number of validation images if necessary\n",
        "num_validation_images = len(val_images)\n",
        "display_images(val_images, val_masks, predictions, num_images=num_validation_images)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KiCeot41uau"
      },
      "source": [
        "## Applied Pretrained Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "04QwFLQhIVO6"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Conv2D, UpSampling2D, Concatenate, Input\n",
        "\n",
        "def unet_with_pretrained_resnet(input_size=(256, 256, 3)):\n",
        "    inputs = Input(input_size)\n",
        "    base_model = ResNet50(weights='imagenet', include_top=False, input_tensor=inputs)\n",
        "\n",
        "    # Encoder\n",
        "    conv1 = base_model.get_layer('conv1_relu').output  # 64x64x64\n",
        "    conv2 = base_model.get_layer('conv2_block3_out').output  # 32x32x256\n",
        "    conv3 = base_model.get_layer('conv3_block4_out').output  # 16x16x512\n",
        "    conv4 = base_model.get_layer('conv4_block6_out').output  # 8x8x1024\n",
        "    conv5 = base_model.get_layer('conv5_block3_out').output  # 4x4x2048\n",
        "\n",
        "    # Bottleneck\n",
        "    bottleneck = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n",
        "\n",
        "    # Decoder\n",
        "    up6 = UpSampling2D(size=(2, 2))(bottleneck)\n",
        "    merge6 = Concatenate()([conv4, up6])\n",
        "    conv6 = Conv2D(512, (3, 3), activation='relu', padding='same')(merge6)\n",
        "\n",
        "    up7 = UpSampling2D(size=(2, 2))(conv6)\n",
        "    merge7 = Concatenate()([conv3, up7])\n",
        "    conv7 = Conv2D(256, (3, 3), activation='relu', padding='same')(merge7)\n",
        "\n",
        "    up8 = UpSampling2D(size=(2, 2))(conv7)\n",
        "    merge8 = Concatenate()([conv2, up8])\n",
        "    conv8 = Conv2D(128, (3, 3), activation='relu', padding='same')(merge8)\n",
        "\n",
        "    up9 = UpSampling2D(size=(2, 2))(conv8)\n",
        "    merge9 = Concatenate()([conv1, up9])\n",
        "    conv9 = Conv2D(64, (3, 3), activation='relu', padding='same')(merge9)\n",
        "\n",
        "    up10 = UpSampling2D(size=(2, 2))(conv9)\n",
        "    conv10 = Conv2D(64, (3, 3), activation='relu', padding='same')(up10)\n",
        "    conv11 = Conv2D(1, (1, 1), activation='sigmoid')(conv10)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=conv11)\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "model = unet_with_pretrained_resnet()\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iPfuSCTVyOIP"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import rasterio\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "def load_tiff_image(file_path):\n",
        "    with rasterio.open(file_path) as src:\n",
        "        return src.read().transpose(1, 2, 0)\n",
        "\n",
        "def preprocess_images(images_path, masks_path, image_size):\n",
        "    images = []\n",
        "    masks = []\n",
        "\n",
        "    image_files = sorted([os.path.join(images_path, f) for f in os.listdir(images_path) if f.endswith('.tif')])\n",
        "    mask_files = sorted([os.path.join(masks_path, f) for f in os.listdir(masks_path) if f.endswith('.tif')])\n",
        "\n",
        "    for img_file, mask_file in zip(image_files, mask_files):\n",
        "        image = load_tiff_image(img_file)\n",
        "        mask = load_tiff_image(mask_file)\n",
        "\n",
        "        image = cv2.resize(image, (image_size, image_size))\n",
        "        mask = cv2.resize(mask, (image_size, image_size))\n",
        "\n",
        "        images.append(image)\n",
        "        masks.append(mask)\n",
        "\n",
        "    return np.array(images), np.array(masks)\n",
        "\n",
        "image_size = 256\n",
        "train_images, train_masks = preprocess_images('/content/drive/MyDrive/Patches/train/rgb',\n",
        "                                              '/content/drive/MyDrive/Patches/train/mask',\n",
        "                                              image_size)\n",
        "\n",
        "val_images, val_masks = preprocess_images('/content/drive/MyDrive/Patches/val/rgb',\n",
        "                                          '/content/drive/MyDrive/Patches/val/mask',\n",
        "                                          image_size)\n",
        "\n",
        "train_masks = np.expand_dims(train_masks, axis=-1)\n",
        "val_masks = np.expand_dims(val_masks, axis=-1)\n",
        "\n",
        "# model = unet_with_pretrained_resnet()\n",
        "# model.summary()\n",
        "\n",
        "# Training the model\n",
        "model.fit(train_images, train_masks, validation_data=(val_images, val_masks), epochs=50, batch_size=8)\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict(val_images)\n",
        "\n",
        "# Visualization function\n",
        "def display_images(images, masks, predictions, num_images=3):\n",
        "    num_images = min(num_images, len(images))  # Ensure num_images does not exceed the length of images\n",
        "\n",
        "    for i in range(num_images):\n",
        "        plt.figure(figsize=(15, 5))\n",
        "\n",
        "        plt.subplot(1, 3, 1)\n",
        "        plt.imshow(images[i])\n",
        "        plt.title('Original Image')\n",
        "\n",
        "        plt.subplot(1, 3, 2)\n",
        "        plt.imshow(masks[i].squeeze(), cmap='gray')\n",
        "        plt.title('Mask')\n",
        "\n",
        "        plt.subplot(1, 3, 3)\n",
        "        plt.imshow(predictions[i].squeeze(), cmap='gray')\n",
        "        plt.title('Prediction')\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "# Adjust num_images to the actual number of validation images if necessary\n",
        "num_validation_images = len(val_images)\n",
        "display_images(val_images, val_masks, predictions, num_images=num_validation_images)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igi5jn4H2bFM"
      },
      "source": [
        "## Applied PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bAYZm77d2alz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6rYiJtB62aqz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sk0HMFIo2atM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-iNnwoUM2avu"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}